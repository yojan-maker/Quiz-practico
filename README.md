# üéØ Quiz_Practico_Tercer_Corte ‚Äî Detecci√≥n de Postura con MediaPipe, Hilos y Streamlit

**Autor:** Yojan Contreras (`yojan-maker`)  
**DockerHub:** `yojancg`  
**Fecha:** (a√±ade la fecha de entrega)

Peque√±a aplicaci√≥n que utiliza **MediaPipe Pose** para detectar en tiempo real dos posturas humanas: **De pie** üßç y **Sentado** üí∫.  
La app muestra la segmentaci√≥n (landmarks y conexiones) sobre el video, etiqueta la postura, y est√° implementada con **concurrencia** (hilos), **sincronizaci√≥n** (mutex/Condition/semaphore) y desplegada con **Streamlit** y **Docker**.

---
## üßæ Descripci√≥n de los componentes principales

- **app.py**  
  - Contiene la interfaz Streamlit y la l√≥gica para iniciar/mostrar la detecci√≥n.
  - Crea 2 hilos:
    - `capturar_video()` ‚Äî captura frames desde la c√°mara (OpenCV).
    - `procesar_postura()` ‚Äî aplica MediaPipe, dibuja landmarks/conexiones y decide la etiqueta.
  - Usa variables compartidas (`frame_compartido`, `etiqueta`) protegidas por **mutex** y sincronizadas con **semaphore** y **Condition**.

- **Dockerfile**  
  - Contiene instrucciones para construir una imagen que ejecute Streamlit + OpenCV + MediaPipe.
  - Incluye paquetes del sistema necesarios para el acceso a la c√°mara.

- **requirements.txt**  
  - Lista de dependencias: `streamlit`, `mediapipe`, `opencv-python`, `numpy` (si procede).

---

## üîß Instalaci√≥n y ejecuci√≥n (local - sin Docker)

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/yojan-maker/Quiz_Practico_Tercer_Corte.git
   cd Quiz_Practico_Tercer_Corte

2. (Recomendado) Crear un entorno virtual:
  ```bash
  python3 -m venv venv
  source venv/bin/activate
  ```
3. Instalar dependencias:
    ```bash
    pip install -r requirements.txt
   ```
4. Ejecutar Streamlit:
  ```bash
  streamlit run app.py
  ```
- Abrir en el navegador: http://localhost:8501
- Pulsa Iniciar detecci√≥n (o el bot√≥n que tenga la UI).

---

## üê≥ Ejecuci√≥n en Docker (con c√°mara)

1. Construir la imagen:
  ```bash
  docker build -t quiz_pose .
  ```
2. Ejecutar el contenedor con acceso a la c√°mara:
  ```bash
  docker run -p 8501:8501 --device /dev/video0:/dev/video0 quiz_pose
  ```
  - Si tu c√°mara est√° en otro device cambia /dev/video0.
  - Abrir http://localhost:8501.
---

## üß† Dise√±o concurrente (hilos y sincronizaci√≥n)

**Variables compartidas**

- frame_compartido ‚Äî frame actual capturado por la c√°mara.
- etiqueta ‚Äî string con la postura detectada.

### **Hilos**

- **Hilo captura (capturar_video()):**
Lee frames de la c√°mara con OpenCV y escribe frame_compartido.
Despu√©s de escribir, notifica al hilo de procesamiento (ej. semaphore.release()).

- **Hilo procesamiento (procesar_postura()):**
Espera a que haya un nuevo frame (semaphore.acquire()), lee frame_compartido, procesa con MediaPipe, dibuja landmarks y actualiza etiqueta.

### **Sincronizaci√≥n**
**Mutex (Lock):**
- mutex = threading.Lock() protege el acceso a frame_compartido y etiqueta.
- Se usa with mutex: alrededor de lecturas/escrituras cr√≠ticas para evitar condiciones de carrera.

**Condition / Semaphore:**
- semaphore (o Condition) coordina los hilos para que el procesador espere hasta que haya un frame nuevo, evitando loops ocupados (busy-wait).
- Ejemplo: semaphore.release() despu√©s de capturar; semaphore.acquire() antes de procesar.

## **Secci√≥n cr√≠tica**
- Todo bloque with mutex: que modifica o recorre enemigos o frame_compartido es secci√≥n cr√≠tica.
---
## üìã Tabla resumen de concurrencia

| **Concepto**              | **Implementaci√≥n**                     | **Funci√≥n**                                  |
|----------------------------|----------------------------------------|----------------------------------------------|
| **Recurso compartido**     | `frame_compartido`, `etiqueta`         | Datos entre captura y procesado              |
| **Mutex (Lock)**           | `mutex = threading.Lock()`             | Exclusi√≥n mutua en accesos cr√≠ticos          |
| **Sem√°foro / Condition**   | `semaphore.acquire()/release()`        | Sincroniza disponibilidad del frame          |
| **Hilo captura**           | `capturar_video()`                     | Produce frames                               |
| **Hilo procesado**         | `procesar_postura()`                   | Consume frames y calcula etiqueta            |

---

### **‚úÖ Detecci√≥n de posturas (l√≥gica simplificada)**

- Uso de landmarks de MediaPipe:
- Ejemplo de comprobaci√≥n: comparar la coordenada y de la cadera con la rodilla.
- Regla simple (ajustable):
    if hip_y < knee_y - umbral: De pie
    else: Sentado
Se recomienda calibrar umbral con pruebas reales para mejorar precisi√≥n.
---

### üß© Visualizaci√≥n (segmentaci√≥n y landmarks)
- El ejemplo usa mp.solutions.drawing_utils.draw_landmarks() para pintar:
    puntos (landmarks) con DrawingSpec(circle_radius=, color=...)
    conexiones (POSE_CONNECTIONS) con connection_drawing_spec.
- El frame con los dibujos se muestra en Streamlit como imagen convertida BGR->RGB.
---

### üì¶ Dockerfile recomendado (ejemplo)
  ```bash
FROM python:3.10-slim
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    libgl1 \
    libglib2.0-0 \
    v4l-utils \
    && rm -rf /var/lib/apt/lists/*
WORKDIR /app
COPY . /app
RUN pip install --no-cache-dir -r requirements.txt
EXPOSE 8501
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```
Ejecutar
  ```bash
docker build -t quiz_pose .
docker run -p 8501:8501 --device /dev/video0:/dev/video0 quiz_pose
```
---
### üì∏ Registro fotogr√°fico

![Image](https://github.com/user-attachments/assets/c84a30b4-3801-48cc-970c-ff02b9e0ec76)

![Image](https://github.com/user-attachments/assets/cc38cc58-a815-4ed9-96d8-b954f3c989d4)


---
## üß© Conclusi√≥n

- La implementaci√≥n desarrollada integra de forma efectiva **MediaPipe Pose**, **Python** y **Streamlit**, demostrando c√≥mo las herramientas de visi√≥n por computadora pueden complementarse con conceptos de **programaci√≥n concurrente** para lograr una aplicaci√≥n funcional, eficiente y modular.

- El uso de **MediaPipe** permiti√≥ realizar la **detecci√≥n de puntos de referencia corporales (landmarks)** en tiempo real, posibilitando la identificaci√≥n precisa de dos posturas humanas b√°sicas: **de pie** y **sentado**. Gracias a la API de MediaPipe, se logr√≥ visualizar los puntos clave y las conexiones del esqueleto corporal, lo que brinda una interpretaci√≥n visual intuitiva del an√°lisis postural.

- Por otra parte, la aplicaci√≥n de **hilos (threads)** permiti√≥ separar las tareas de captura de video y procesamiento de pose, optimizando el rendimiento y evitando bloqueos del flujo principal. - La incorporaci√≥n de **mutex**, **secci√≥n cr√≠tica** y **semaforizaci√≥n** garantiz√≥ la sincronizaci√≥n adecuada entre los hilos, evitando condiciones de carrera y asegurando la consistencia de los datos compartidos.

- En conjunto, este proyecto demuestra c√≥mo combinar **t√©cnicas de visi√≥n artificial**, **sincronizaci√≥n concurrente** y **contenedorizaci√≥n** para crear sistemas interactivos y robustos basados en inteligencia artificial aplicada.

---
### Creditos
## üôå Cr√©ditos

Este proyecto hace uso de la tecnolog√≠a de **MediaPipe Pose Landmarker**, desarrollada por **Google Research** dentro del framework **MediaPipe**.  
El sistema de detecci√≥n de puntos de referencia corporales y la segmentaci√≥n visual est√°n basados en el modelo original disponible en:

üîó [MediaPipe Studio ‚Äì Pose Landmarker Demo](https://mediapipe-studio.webapps.google.com/demo/pose_landmarker?hl=es-419)

Se agradece a la comunidad de desarrolladores de **MediaPipe** por proporcionar herramientas abiertas que facilitan la integraci√≥n de modelos de visi√≥n por computadora en aplicaciones interactivas, fomentando el aprendizaje y la experimentaci√≥n en el campo de la inteligencia artificial aplicada.
